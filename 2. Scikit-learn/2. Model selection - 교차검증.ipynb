{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07dca41",
   "metadata": {},
   "source": [
    "## K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326f8d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris data 크기 : 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "#KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "print(\"iris data 크기 :\",features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838d73a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ##1 교차 검증 정확도 : 1.0, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "   1 검증 세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      " ##2 교차 검증 정확도 : 0.9667, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "   2 검증 세트 인덱스 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      " ##3 교차 검증 정확도 : 0.8667, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "   3 검증 세트 인덱스 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      " ##4 교차 검증 정확도 : 0.9333, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "   4 검증 세트 인덱스 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      " ##5 교차 검증 정확도 : 0.7333, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "   5 검증 세트 인덱스 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " 평균 검증 정확도 :  0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "#KFold 객체의 split()를 호출하면 폴드 별 학습, 검증용 테스트의 로우 인덱스를 array로 반환\n",
    "for train_index, test_index, in kfold.split(features):\n",
    "    \n",
    "    #반환된 인덱스를 이용해 학습, 검증용 테스트 데이터 추출\n",
    "    X_train,X_test = features[train_index],features[test_index]\n",
    "    y_train,y_test = label[train_index],label[test_index]\n",
    "    \n",
    "    #학습, 예측\n",
    "    dt.fit(X_train,y_train)\n",
    "    pred = dt.predict(X_test)\n",
    "    n_iter+=1\n",
    "    \n",
    "    #반복 시마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print('\\n ##{0} 교차 검증 정확도 : {1}, 학습 데이터 크기 : {2}, 검증 데이터 크기 : {3}'.format(n_iter,accuracy,train_size,test_size))\n",
    "    print('   {0} 검증 세트 인덱스 : {1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "#평균 정확도 계산\n",
    "print('\\n 평균 검증 정확도 : ',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff574f",
   "metadata": {},
   "source": [
    "Stratified KFold\n",
    " - 불균형 분포를 가진 데이터 집합을 위한 KFold\n",
    " - 호출시 반드시 레이블 데이터 셋도 추가 입력 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4550fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data = iris.data,columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccff2a6d",
   "metadata": {},
   "source": [
    "불균형하게 3개의 폴드 세트를 KFold로 생성하고 검증 시마다 생성되는 학습/검증 레이블 데이터 값의 분포도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18fb5fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "\n",
      "#교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "\n",
      "#교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter+=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(\"\\n#교차 검증 : {0}\".format(n_iter))\n",
    "    print(\"학습 레이블 데이터 분포 : \\n\",label_train.value_counts())\n",
    "    print(\"검증 레이블 데이터 분포 : \\n\",label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9418bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#교차검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "\n",
      "#교차검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "\n",
      "#교차검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df,iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(\"\\n#교차검증 : {0}\".format(n_iter))\n",
    "    print(\"학습 레이블 데이터 분포 : \\n\",label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 : \\n',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ed879be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 교차 검증 정확도 : 0.98, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
      "1 검증 세트 인덱스 : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "2 교차 검증 정확도 : 0.94, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
      "2 검증 세트 인덱스 : [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "3 교차 검증 정확도 : 0.98, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
      "3 검증 세트 인덱스 : [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " 교차 검증별 정확도 :  [0.98 0.94 0.98]\n",
      "평균 검증 정확도 :  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=156)\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index, test_index in skfold.split(features,label):\n",
    "    X_train,X_test = features[train_index],features[test_index]\n",
    "    y_train,y_test = label[train_index],label[test_index]\n",
    "    \n",
    "    dt.fit(X_train,y_train)\n",
    "    pred = dt.predict(X_test)\n",
    "    \n",
    "    #반복마다 정확도 측정\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n{0} 교차 검증 정확도 : {1}, 학습 데이터 크기 : {2}, 검증 데이터 크기 : {3}'\n",
    "         .format(n_iter,accuracy,train_size,test_size))\n",
    "    print(\"{0} 검증 세트 인덱스 : {1}\".format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    " \n",
    "\n",
    "#교차 검증별 정확도 및 평균 정확도\n",
    "print(\"\\n 교차 검증별 정확도 : \",np.round(cv_accuracy,4))\n",
    "print(\"평균 검증 정확도 : \",np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c5797",
   "metadata": {},
   "source": [
    "## cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c306bdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 :  [0.98 0.94 0.98]\n",
      "평균 검증 정확도 :  0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt = DecisionTreeClassifier(random_state=156)\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "scores = cross_val_score(dt,data,label,scoring = 'accuracy',cv = 3)\n",
    "\n",
    "print(\"교차 검증별 정확도 : \",np.round(scores,4))\n",
    "print(\"평균 검증 정확도 : \",np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c7fe4",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b22d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "\n",
    "iris_data = load_iris()\n",
    "X_train,X_test,y_train,y_test = train_test_split(iris_data.data,iris_data.target,test_size=0.2,random_state=121)\n",
    "\n",
    "grid_parameters = {'max_depth' : [1,2,3],\n",
    "                  'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a7e0505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "grid_dtree = GridSearchCV(dt,param_grid=grid_parameters,cv=3,refit=True)\n",
    "\n",
    "grid_dtree.fit(X_train,y_train)\n",
    "\n",
    "#순차적으로 하이퍼 파라미터 학습, 평가\n",
    "scores = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d20f5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridsearchCV 최적 파라미터 :  {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도 : 0.9750\n"
     ]
    }
   ],
   "source": [
    "print(\"GridsearchCV 최적 파라미터 : \",grid_dtree.best_params_)\n",
    "print(\"GridSearchCV 최고 정확도 : {0:.4f}\".format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab87ae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 정확도 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "#refit으로 이미 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "#GridSearchCV의 best_estimator는 이미 최적 학습이므로 별도 학습이 필요하지 않음\n",
    "pred = estimator.predict(X_test)\n",
    "print(\"테스트데이터 정확도 : {0:.4f}\".format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21b081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
